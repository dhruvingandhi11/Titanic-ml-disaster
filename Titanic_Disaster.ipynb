{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic Disaster.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOcZGD/AbT/7PQGHgC1/ZSN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhruvingandhi11/Titanic-ml-disaster/blob/master/Titanic_Disaster.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_N2ElvksBHI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a0c02d7a-675a-4fe3-e9ea-57b028a5346f"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsApePWK2xtm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ac6a274d-d2bf-4e2c-e197-b133eb93f472"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5mnj-d13Bhp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Titanic problem/train.csv')\n",
        "df1 = pd.read_csv('/content/drive/My Drive/Titanic problem/test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbsQCljO3eIT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "d8633b0f-1bb8-494f-afed-756295452b5a"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "0            1         0       3  ...   7.2500   NaN         S\n",
              "1            2         1       1  ...  71.2833   C85         C\n",
              "2            3         1       3  ...   7.9250   NaN         S\n",
              "3            4         1       1  ...  53.1000  C123         S\n",
              "4            5         0       3  ...   8.0500   NaN         S\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GziQLmdW3gI4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "f5308cd1-97fa-4d38-e316-b15a6eb3d409"
      },
      "source": [
        "df1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>892</td>\n",
              "      <td>3</td>\n",
              "      <td>Kelly, Mr. James</td>\n",
              "      <td>male</td>\n",
              "      <td>34.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330911</td>\n",
              "      <td>7.8292</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>893</td>\n",
              "      <td>3</td>\n",
              "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
              "      <td>female</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>363272</td>\n",
              "      <td>7.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>894</td>\n",
              "      <td>2</td>\n",
              "      <td>Myles, Mr. Thomas Francis</td>\n",
              "      <td>male</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>240276</td>\n",
              "      <td>9.6875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>895</td>\n",
              "      <td>3</td>\n",
              "      <td>Wirz, Mr. Albert</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>315154</td>\n",
              "      <td>8.6625</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>896</td>\n",
              "      <td>3</td>\n",
              "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
              "      <td>female</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3101298</td>\n",
              "      <td>12.2875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Pclass  ... Cabin Embarked\n",
              "0          892       3  ...   NaN        Q\n",
              "1          893       3  ...   NaN        S\n",
              "2          894       2  ...   NaN        Q\n",
              "3          895       3  ...   NaN        S\n",
              "4          896       3  ...   NaN        S\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2qnd5U63jcX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfy = df.Survived\n",
        "\n",
        "df.drop(['PassengerId','Survived','Name','Ticket','Cabin','Fare'],axis=1,inplace=True)\n",
        "df1.drop(['PassengerId','Name','Ticket','Cabin','Fare'],axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2j5KCGMX3qnb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "694e7932-5ed8-4764-a74a-9068ca980cfe"
      },
      "source": [
        "dfy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0\n",
              "1      1\n",
              "2      1\n",
              "3      1\n",
              "4      0\n",
              "      ..\n",
              "886    0\n",
              "887    1\n",
              "888    0\n",
              "889    1\n",
              "890    0\n",
              "Name: Survived, Length: 891, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJxic_RA3tfZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "358e2a6f-660a-45c6-bf2f-71bae1838cbc"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pclass     Sex   Age  SibSp  Parch Embarked\n",
              "0       3    male  22.0      1      0        S\n",
              "1       1  female  38.0      1      0        C\n",
              "2       3  female  26.0      0      0        S\n",
              "3       1  female  35.0      1      0        S\n",
              "4       3    male  35.0      0      0        S"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZhBRVuX3xxl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2848aa38-2257-44f8-eed5-6f4b66cda21b"
      },
      "source": [
        "df1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>34.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>male</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pclass     Sex   Age  SibSp  Parch Embarked\n",
              "0       3    male  34.5      0      0        Q\n",
              "1       3  female  47.0      1      0        S\n",
              "2       2    male  62.0      0      0        Q\n",
              "3       3    male  27.0      0      0        S\n",
              "4       3  female  22.0      1      1        S"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neLNoat631iy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "18cf9f27-8a48-48b3-a016-8814fcc6cc14"
      },
      "source": [
        "print('shape of training data: ',df.shape)\n",
        "print('shape of testing data: ',df1.shape )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of training data:  (891, 6)\n",
            "shape of testing data:  (418, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTxSAtQB4KSA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "a44bc939-cf85-4eaa-a1a4-2dccd30af536"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 6 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   Pclass    891 non-null    int64  \n",
            " 1   Sex       891 non-null    object \n",
            " 2   Age       714 non-null    float64\n",
            " 3   SibSp     891 non-null    int64  \n",
            " 4   Parch     891 non-null    int64  \n",
            " 5   Embarked  889 non-null    object \n",
            "dtypes: float64(1), int64(3), object(2)\n",
            "memory usage: 41.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVUBhBu94S5p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "2a3a2084-5725-4036-e6fa-cb3dc04c0b37"
      },
      "source": [
        "df1.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 418 entries, 0 to 417\n",
            "Data columns (total 6 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   Pclass    418 non-null    int64  \n",
            " 1   Sex       418 non-null    object \n",
            " 2   Age       332 non-null    float64\n",
            " 3   SibSp     418 non-null    int64  \n",
            " 4   Parch     418 non-null    int64  \n",
            " 5   Embarked  418 non-null    object \n",
            "dtypes: float64(1), int64(3), object(2)\n",
            "memory usage: 19.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FHk37dS4VAW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "61e7f0d4-d129-4e9e-c405-f93357c8dd36"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>714.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.308642</td>\n",
              "      <td>29.699118</td>\n",
              "      <td>0.523008</td>\n",
              "      <td>0.381594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.836071</td>\n",
              "      <td>14.526497</td>\n",
              "      <td>1.102743</td>\n",
              "      <td>0.806057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>20.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Pclass         Age       SibSp       Parch\n",
              "count  891.000000  714.000000  891.000000  891.000000\n",
              "mean     2.308642   29.699118    0.523008    0.381594\n",
              "std      0.836071   14.526497    1.102743    0.806057\n",
              "min      1.000000    0.420000    0.000000    0.000000\n",
              "25%      2.000000   20.125000    0.000000    0.000000\n",
              "50%      3.000000   28.000000    0.000000    0.000000\n",
              "75%      3.000000   38.000000    1.000000    0.000000\n",
              "max      3.000000   80.000000    8.000000    6.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3xdP7e953q3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "ef71fda2-6d28-4350-eafb-62fd82743677"
      },
      "source": [
        "df1.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>418.000000</td>\n",
              "      <td>332.000000</td>\n",
              "      <td>418.000000</td>\n",
              "      <td>418.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.265550</td>\n",
              "      <td>30.272590</td>\n",
              "      <td>0.447368</td>\n",
              "      <td>0.392344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.841838</td>\n",
              "      <td>14.181209</td>\n",
              "      <td>0.896760</td>\n",
              "      <td>0.981429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.170000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>9.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Pclass         Age       SibSp       Parch\n",
              "count  418.000000  332.000000  418.000000  418.000000\n",
              "mean     2.265550   30.272590    0.447368    0.392344\n",
              "std      0.841838   14.181209    0.896760    0.981429\n",
              "min      1.000000    0.170000    0.000000    0.000000\n",
              "25%      1.000000   21.000000    0.000000    0.000000\n",
              "50%      3.000000   27.000000    0.000000    0.000000\n",
              "75%      3.000000   39.000000    1.000000    0.000000\n",
              "max      3.000000   76.000000    8.000000    9.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ek9pW3Np56yv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4aed98a0-8ff3-45da-d4a2-267cf8c9a4ea"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiITBp327QDw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "1d8c466f-ce8a-4f60-caf8-eb0bdb7abcb0"
      },
      "source": [
        "column_df = df.columns\n",
        "\n",
        "for x in column_df:\n",
        "  print('unique value information: ',x)\n",
        "  # print(df[x].unique())\n",
        "  print('number of unique values: ',df[x].unique().shape[0])\n",
        "  print('number of null (True if value is NaN) : \\n',df[x].isnull().value_counts())\n",
        "  print('\\n-----------------------------------------------------------------\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unique value information:  Pclass\n",
            "number of unique values:  3\n",
            "number of null (True if value is NaN) : \n",
            " False    891\n",
            "Name: Pclass, dtype: int64\n",
            "\n",
            "-----------------------------------------------------------------\n",
            "\n",
            "unique value information:  Sex\n",
            "number of unique values:  2\n",
            "number of null (True if value is NaN) : \n",
            " False    891\n",
            "Name: Sex, dtype: int64\n",
            "\n",
            "-----------------------------------------------------------------\n",
            "\n",
            "unique value information:  Age\n",
            "number of unique values:  89\n",
            "number of null (True if value is NaN) : \n",
            " False    714\n",
            "True     177\n",
            "Name: Age, dtype: int64\n",
            "\n",
            "-----------------------------------------------------------------\n",
            "\n",
            "unique value information:  SibSp\n",
            "number of unique values:  7\n",
            "number of null (True if value is NaN) : \n",
            " False    891\n",
            "Name: SibSp, dtype: int64\n",
            "\n",
            "-----------------------------------------------------------------\n",
            "\n",
            "unique value information:  Parch\n",
            "number of unique values:  7\n",
            "number of null (True if value is NaN) : \n",
            " False    891\n",
            "Name: Parch, dtype: int64\n",
            "\n",
            "-----------------------------------------------------------------\n",
            "\n",
            "unique value information:  Embarked\n",
            "number of unique values:  4\n",
            "number of null (True if value is NaN) : \n",
            " False    889\n",
            "True       2\n",
            "Name: Embarked, dtype: int64\n",
            "\n",
            "-----------------------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5UT7bIx-1h6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "outputId": "8ebfa666-c960-4e8e-be75-689c0be3a7cc"
      },
      "source": [
        "columns_df1 = df1.columns\n",
        "\n",
        "for x in columns_df1:\n",
        "  print('unique value information: ',x)\n",
        "  #print(df1[x].unique())\n",
        "  print('number of unique values: ',df1[x].unique().shape[0])\n",
        "  print('number of null (True if value is NaN): \\n',df1[x].isnull().value_counts())\n",
        "  print('\\n-------------------------------------------------------------\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unique value information:  Pclass\n",
            "number of unique values:  3\n",
            "number of null (True if value is NaN): \n",
            " False    418\n",
            "Name: Pclass, dtype: int64\n",
            "\n",
            "-------------------------------------------------------------\n",
            "\n",
            "unique value information:  Sex\n",
            "number of unique values:  2\n",
            "number of null (True if value is NaN): \n",
            " False    418\n",
            "Name: Sex, dtype: int64\n",
            "\n",
            "-------------------------------------------------------------\n",
            "\n",
            "unique value information:  Age\n",
            "number of unique values:  80\n",
            "number of null (True if value is NaN): \n",
            " False    332\n",
            "True      86\n",
            "Name: Age, dtype: int64\n",
            "\n",
            "-------------------------------------------------------------\n",
            "\n",
            "unique value information:  SibSp\n",
            "number of unique values:  7\n",
            "number of null (True if value is NaN): \n",
            " False    418\n",
            "Name: SibSp, dtype: int64\n",
            "\n",
            "-------------------------------------------------------------\n",
            "\n",
            "unique value information:  Parch\n",
            "number of unique values:  8\n",
            "number of null (True if value is NaN): \n",
            " False    418\n",
            "Name: Parch, dtype: int64\n",
            "\n",
            "-------------------------------------------------------------\n",
            "\n",
            "unique value information:  Embarked\n",
            "number of unique values:  3\n",
            "number of null (True if value is NaN): \n",
            " False    418\n",
            "Name: Embarked, dtype: int64\n",
            "\n",
            "-------------------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-_v8VZACELS",
        "colab_type": "text"
      },
      "source": [
        "## Replace **NaN** with **mean** **Value** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GRpTvrVCqhi",
        "colab_type": "text"
      },
      "source": [
        "Age in df and df1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MrTxhfMChQP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "785303a2-7d38-4e57-9fe1-02fa13ccc33f"
      },
      "source": [
        "df.Age.isnull().value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    714\n",
              "True     177\n",
              "Name: Age, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49CgyVsIDNw6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.Age.fillna(df.Age.mean(),inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdtydxOnFtXQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cd599c78-c09b-43b8-f337-19aa897bd9d7"
      },
      "source": [
        "df.Age.isnull().value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    891\n",
              "Name: Age, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zuq_IgJF6O6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c45fd39b-f249-4fa3-ed38-11bcbabf7264"
      },
      "source": [
        "df1.Age.isnull().value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    332\n",
              "True      86\n",
              "Name: Age, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxEk-mDnGGZi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1.Age.fillna(df1.Age.mean(), inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIkeoXZRGTDL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e66f0b8d-ceac-4528-d26b-73810021407b"
      },
      "source": [
        "df1.Age.isnull().value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    418\n",
              "Name: Age, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUHyARS1GXFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2SgXtA3G4N1",
        "colab_type": "text"
      },
      "source": [
        "## Embarked in df has 2 missing values, replace it by **mode** of that column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnkYcAp1HN5d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e833a0b8-8089-4adb-b6a9-de7fe629ce3c"
      },
      "source": [
        "df.Embarked.isnull().value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    889\n",
              "True       2\n",
              "Name: Embarked, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9imesFd9Hb4n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b81e3560-94d7-4920-b2fd-d4f03c915f03"
      },
      "source": [
        "df.Embarked.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "S    644\n",
              "C    168\n",
              "Q     77\n",
              "Name: Embarked, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wsAcea_HjDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.Embarked.fillna('S',inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_hxADYBH4Gd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a190f62a-a786-439f-8cae-bb3c6cf8687f"
      },
      "source": [
        "df.Embarked.isnull().value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    891\n",
              "Name: Embarked, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwRYdjv8IAyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pi8XZW2pJNgt",
        "colab_type": "text"
      },
      "source": [
        "# labeling of column which contain catagorical data in object data type ('Sex' and 'Embarked')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmKLY6s8JPb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hifbNJySKbt6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le = LabelEncoder()\n",
        "\n",
        "le.fit(df.Sex)\n",
        "Sex_labeled = le.transform(df.Sex)\n",
        "df['Sex_labeled'] = Sex_labeled\n",
        "df.drop(['Sex'],axis = 1, inplace = True)\n",
        "\n",
        "le.fit(df.Embarked)\n",
        "Embarked_labeled = le.transform(df.Embarked)\n",
        "df['Embarked_labeled'] = Embarked_labeled\n",
        "df.drop(['Embarked'],axis =1, inplace = True)\n",
        "\n",
        "le.fit(df1.Sex)\n",
        "Sex_labeled= le.transform(df1.Sex)\n",
        "df1['Sex_labeled'] = Sex_labeled\n",
        "df1.drop(['Sex'], axis =1, inplace =True)\n",
        "\n",
        "le.fit(df1.Embarked)\n",
        "Embarked_labeled = le.transform(df1.Embarked)\n",
        "df1['Embarked_labeled'] = Embarked_labeled\n",
        "df1.drop(['Embarked'], axis =1, inplace =True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYt1mJZepmeH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "dd0554ba-5c37-4099-bd22-52e417df235a"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Sex_labeled</th>\n",
              "      <th>Embarked_labeled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pclass   Age  SibSp  Parch  Sex_labeled  Embarked_labeled\n",
              "0       3  22.0      1      0            1                 2\n",
              "1       1  38.0      1      0            0                 0\n",
              "2       3  26.0      0      0            0                 2\n",
              "3       1  35.0      1      0            0                 2\n",
              "4       3  35.0      0      0            1                 2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ3t0r6UqTEC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8979e134-5094-4fa4-a41e-50c32a692c9f"
      },
      "source": [
        "df1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Sex_labeled</th>\n",
              "      <th>Embarked_labeled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>34.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pclass   Age  SibSp  Parch  Sex_labeled  Embarked_labeled\n",
              "0       3  34.5      0      0            1                 1\n",
              "1       3  47.0      1      0            0                 2\n",
              "2       2  62.0      0      0            1                 1\n",
              "3       3  27.0      0      0            1                 2\n",
              "4       3  22.0      1      1            0                 2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dN-DQThaqVz3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "1d061d42-f04f-4be4-81a2-7517f364d13c"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 6 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   Pclass            891 non-null    int64  \n",
            " 1   Age               891 non-null    float64\n",
            " 2   SibSp             891 non-null    int64  \n",
            " 3   Parch             891 non-null    int64  \n",
            " 4   Sex_labeled       891 non-null    int64  \n",
            " 5   Embarked_labeled  891 non-null    int64  \n",
            "dtypes: float64(1), int64(5)\n",
            "memory usage: 41.9 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpT3autaq07w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "aa3930d2-eda2-491e-f84e-f0d05d292415"
      },
      "source": [
        "df1.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 418 entries, 0 to 417\n",
            "Data columns (total 6 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   Pclass            418 non-null    int64  \n",
            " 1   Age               418 non-null    float64\n",
            " 2   SibSp             418 non-null    int64  \n",
            " 3   Parch             418 non-null    int64  \n",
            " 4   Sex_labeled       418 non-null    int64  \n",
            " 5   Embarked_labeled  418 non-null    int64  \n",
            "dtypes: float64(1), int64(5)\n",
            "memory usage: 19.7 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddMX1qvRq5M1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNvEy9dlq9Ds",
        "colab_type": "text"
      },
      "source": [
        "# Normalizing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr7OUDYsrAik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.array(df)\n",
        "y = np.array(dfy)\n",
        "\n",
        "x1 = np.array(df1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mik-6AGrUSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "x = scaler.fit_transform(x)\n",
        "x1 = scaler.fit_transform(x1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNfjJbZAs7_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLM9vQ2HtEkd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EB_yA2YhtGSp",
        "colab_type": "text"
      },
      "source": [
        "# Train test split df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjryUlfLtJ6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split as tts\n",
        "x_train, x_test, y_train, y_test = tts(df, dfy, test_size =0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yfk7SIAnujS2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "046a05d7-5e6c-4d97-fd45-904a9effb4e7"
      },
      "source": [
        "print('Shape of Train and Test Set: ')\n",
        "print('x_train: ', x_train.shape)\n",
        "print('x_test: ', x_test.shape)\n",
        "print('y_train: ', y_train.shape)\n",
        "print('y_test: ',y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of Train and Test Set: \n",
            "x_train:  (712, 6)\n",
            "x_test:  (179, 6)\n",
            "y_train:  (712,)\n",
            "y_test:  (179,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AU1ecigvvUhW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2uS8vN_wtVw",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JO7ctyqowxYV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier as RFC\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkBFv_z3zpVV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "bdfd5bad-6768-41c4-c789-0f74fcd39250"
      },
      "source": [
        "model_rfc = RFC(max_depth=10, n_estimators =100, random_state = 2)\n",
        "model_rfc.fit(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=10, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=2, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poQNB7Gm3M6W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0c535b66-0a58-466e-f2b3-4113d86f5525"
      },
      "source": [
        "model_rfc.score(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8324022346368715"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RM-9Izsu3UAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model_rfc.predict(df1)\n",
        "#roc_auc_score(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgSdjWIO3kTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOud73db3v8v",
        "colab_type": "text"
      },
      "source": [
        "# SVM Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AFzV1s83zlV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24wfwZAV4R-D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "16a56b6f-6671-419a-f539-f3786f54b28e"
      },
      "source": [
        "model_svm = SVC(C=10)\n",
        "model_svm.fit(df,dfy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyLAsJa65it8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bad4a8e3-2fcb-43c8-c3a4-70d18a958401"
      },
      "source": [
        "model_svm.score(df,dfy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8159371492704826"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCBkVaGX5taP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model_svm.predict(df1)\n",
        "\n",
        "#roc_auc_score(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vF4xtZ-C5x3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttAHin_4526H",
        "colab_type": "text"
      },
      "source": [
        "# Solve by ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOcKam9N57eO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "eb0a7167-1a76-4245-adf8-7209395a94b9"
      },
      "source": [
        "# create Model \n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Dense(12 , activation=\"sigmoid\", input_shape=(6,)))\n",
        "model.add(layers.Dense(6, activation=\"sigmoid\")),\n",
        "model.add(layers.Dense(1,activation=\"sigmoid\"))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 12)                84        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 78        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 169\n",
            "Trainable params: 169\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATpkvM-r7ZE8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "63da5c40-8fcc-4dcd-d15b-9c18cffd2dd5"
      },
      "source": [
        "# fit and compile model\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[keras.metrics.AUC()])\n",
        "\n",
        "history= model.fit(x_train,y_train,batch_size=32,epochs=600,validation_data=(x_test,y_test))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.6645 - auc: 0.4756 - val_loss: 0.6763 - val_auc: 0.5172\n",
            "Epoch 2/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6642 - auc: 0.4545 - val_loss: 0.6746 - val_auc: 0.5099\n",
            "Epoch 3/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6635 - auc: 0.4744 - val_loss: 0.6742 - val_auc: 0.5113\n",
            "Epoch 4/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6633 - auc: 0.5077 - val_loss: 0.6736 - val_auc: 0.4984\n",
            "Epoch 5/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6630 - auc: 0.5201 - val_loss: 0.6734 - val_auc: 0.5356\n",
            "Epoch 6/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6628 - auc: 0.5120 - val_loss: 0.6725 - val_auc: 0.5482\n",
            "Epoch 7/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6624 - auc: 0.5224 - val_loss: 0.6717 - val_auc: 0.5479\n",
            "Epoch 8/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6620 - auc: 0.5205 - val_loss: 0.6712 - val_auc: 0.5169\n",
            "Epoch 9/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6617 - auc: 0.5485 - val_loss: 0.6701 - val_auc: 0.5414\n",
            "Epoch 10/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6612 - auc: 0.5265 - val_loss: 0.6696 - val_auc: 0.5108\n",
            "Epoch 11/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6607 - auc: 0.5063 - val_loss: 0.6687 - val_auc: 0.5619\n",
            "Epoch 12/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6601 - auc: 0.5499 - val_loss: 0.6680 - val_auc: 0.5607\n",
            "Epoch 13/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6597 - auc: 0.5283 - val_loss: 0.6667 - val_auc: 0.5553\n",
            "Epoch 14/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6590 - auc: 0.5256 - val_loss: 0.6658 - val_auc: 0.5726\n",
            "Epoch 15/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6582 - auc: 0.5584 - val_loss: 0.6645 - val_auc: 0.5616\n",
            "Epoch 16/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6577 - auc: 0.5745 - val_loss: 0.6636 - val_auc: 0.5776\n",
            "Epoch 17/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6567 - auc: 0.5915 - val_loss: 0.6621 - val_auc: 0.6115\n",
            "Epoch 18/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6563 - auc: 0.5696 - val_loss: 0.6614 - val_auc: 0.5959\n",
            "Epoch 19/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6549 - auc: 0.6306 - val_loss: 0.6595 - val_auc: 0.6569\n",
            "Epoch 20/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6541 - auc: 0.6505 - val_loss: 0.6582 - val_auc: 0.6315\n",
            "Epoch 21/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6534 - auc: 0.6430 - val_loss: 0.6572 - val_auc: 0.6641\n",
            "Epoch 22/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6524 - auc: 0.6541 - val_loss: 0.6554 - val_auc: 0.6608\n",
            "Epoch 23/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6514 - auc: 0.6663 - val_loss: 0.6542 - val_auc: 0.6681\n",
            "Epoch 24/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6499 - auc: 0.6821 - val_loss: 0.6526 - val_auc: 0.6908\n",
            "Epoch 25/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6486 - auc: 0.6967 - val_loss: 0.6506 - val_auc: 0.7093\n",
            "Epoch 26/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6462 - auc: 0.7144 - val_loss: 0.6470 - val_auc: 0.7298\n",
            "Epoch 27/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6437 - auc: 0.7429 - val_loss: 0.6438 - val_auc: 0.7671\n",
            "Epoch 28/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6408 - auc: 0.7588 - val_loss: 0.6411 - val_auc: 0.7735\n",
            "Epoch 29/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6381 - auc: 0.7764 - val_loss: 0.6385 - val_auc: 0.7877\n",
            "Epoch 30/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6354 - auc: 0.7860 - val_loss: 0.6353 - val_auc: 0.8012\n",
            "Epoch 31/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6326 - auc: 0.7892 - val_loss: 0.6329 - val_auc: 0.7996\n",
            "Epoch 32/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6304 - auc: 0.7876 - val_loss: 0.6293 - val_auc: 0.7987\n",
            "Epoch 33/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6279 - auc: 0.7809 - val_loss: 0.6261 - val_auc: 0.8048\n",
            "Epoch 34/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6251 - auc: 0.7854 - val_loss: 0.6228 - val_auc: 0.8125\n",
            "Epoch 35/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6221 - auc: 0.7829 - val_loss: 0.6194 - val_auc: 0.8204\n",
            "Epoch 36/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6168 - auc: 0.8054 - val_loss: 0.6146 - val_auc: 0.8176\n",
            "Epoch 37/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6140 - auc: 0.8016 - val_loss: 0.6103 - val_auc: 0.8264\n",
            "Epoch 38/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6096 - auc: 0.8096 - val_loss: 0.6057 - val_auc: 0.8257\n",
            "Epoch 39/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6060 - auc: 0.8042 - val_loss: 0.6013 - val_auc: 0.8340\n",
            "Epoch 40/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6021 - auc: 0.8089 - val_loss: 0.5966 - val_auc: 0.8328\n",
            "Epoch 41/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5986 - auc: 0.8059 - val_loss: 0.5924 - val_auc: 0.8313\n",
            "Epoch 42/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5938 - auc: 0.8137 - val_loss: 0.5881 - val_auc: 0.8306\n",
            "Epoch 43/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5901 - auc: 0.8068 - val_loss: 0.5832 - val_auc: 0.8321\n",
            "Epoch 44/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5856 - auc: 0.8131 - val_loss: 0.5782 - val_auc: 0.8333\n",
            "Epoch 45/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5822 - auc: 0.8125 - val_loss: 0.5736 - val_auc: 0.8431\n",
            "Epoch 46/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5789 - auc: 0.8129 - val_loss: 0.5693 - val_auc: 0.8429\n",
            "Epoch 47/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5743 - auc: 0.8164 - val_loss: 0.5648 - val_auc: 0.8427\n",
            "Epoch 48/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5713 - auc: 0.8135 - val_loss: 0.5604 - val_auc: 0.8424\n",
            "Epoch 49/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5684 - auc: 0.8131 - val_loss: 0.5565 - val_auc: 0.8455\n",
            "Epoch 50/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5633 - auc: 0.8141 - val_loss: 0.5531 - val_auc: 0.8462\n",
            "Epoch 51/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5597 - auc: 0.8143 - val_loss: 0.5482 - val_auc: 0.8444\n",
            "Epoch 52/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5562 - auc: 0.8184 - val_loss: 0.5431 - val_auc: 0.8514\n",
            "Epoch 53/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5525 - auc: 0.8196 - val_loss: 0.5395 - val_auc: 0.8493\n",
            "Epoch 54/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5489 - auc: 0.8193 - val_loss: 0.5351 - val_auc: 0.8445\n",
            "Epoch 55/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5456 - auc: 0.8229 - val_loss: 0.5315 - val_auc: 0.8514\n",
            "Epoch 56/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5425 - auc: 0.8183 - val_loss: 0.5278 - val_auc: 0.8485\n",
            "Epoch 57/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5392 - auc: 0.8204 - val_loss: 0.5236 - val_auc: 0.8483\n",
            "Epoch 58/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5362 - auc: 0.8208 - val_loss: 0.5204 - val_auc: 0.8517\n",
            "Epoch 59/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5323 - auc: 0.8216 - val_loss: 0.5168 - val_auc: 0.8505\n",
            "Epoch 60/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5291 - auc: 0.8223 - val_loss: 0.5127 - val_auc: 0.8558\n",
            "Epoch 61/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5267 - auc: 0.8234 - val_loss: 0.5090 - val_auc: 0.8548\n",
            "Epoch 62/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5237 - auc: 0.8257 - val_loss: 0.5067 - val_auc: 0.8572\n",
            "Epoch 63/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5238 - auc: 0.8224 - val_loss: 0.5043 - val_auc: 0.8543\n",
            "Epoch 64/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5190 - auc: 0.8260 - val_loss: 0.4995 - val_auc: 0.8568\n",
            "Epoch 65/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5163 - auc: 0.8259 - val_loss: 0.4959 - val_auc: 0.8573\n",
            "Epoch 66/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5126 - auc: 0.8282 - val_loss: 0.4932 - val_auc: 0.8529\n",
            "Epoch 67/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5103 - auc: 0.8261 - val_loss: 0.4900 - val_auc: 0.8560\n",
            "Epoch 68/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5081 - auc: 0.8299 - val_loss: 0.4869 - val_auc: 0.8591\n",
            "Epoch 69/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5060 - auc: 0.8303 - val_loss: 0.4850 - val_auc: 0.8627\n",
            "Epoch 70/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5038 - auc: 0.8314 - val_loss: 0.4819 - val_auc: 0.8623\n",
            "Epoch 71/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5023 - auc: 0.8293 - val_loss: 0.4790 - val_auc: 0.8601\n",
            "Epoch 72/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4990 - auc: 0.8348 - val_loss: 0.4775 - val_auc: 0.8644\n",
            "Epoch 73/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4969 - auc: 0.8326 - val_loss: 0.4753 - val_auc: 0.8607\n",
            "Epoch 74/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4947 - auc: 0.8339 - val_loss: 0.4717 - val_auc: 0.8648\n",
            "Epoch 75/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4938 - auc: 0.8327 - val_loss: 0.4707 - val_auc: 0.8581\n",
            "Epoch 76/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4921 - auc: 0.8325 - val_loss: 0.4679 - val_auc: 0.8590\n",
            "Epoch 77/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4893 - auc: 0.8328 - val_loss: 0.4659 - val_auc: 0.8653\n",
            "Epoch 78/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4871 - auc: 0.8365 - val_loss: 0.4629 - val_auc: 0.8616\n",
            "Epoch 79/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4860 - auc: 0.8377 - val_loss: 0.4605 - val_auc: 0.8620\n",
            "Epoch 80/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4839 - auc: 0.8390 - val_loss: 0.4580 - val_auc: 0.8616\n",
            "Epoch 81/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4832 - auc: 0.8400 - val_loss: 0.4591 - val_auc: 0.8634\n",
            "Epoch 82/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4800 - auc: 0.8395 - val_loss: 0.4549 - val_auc: 0.8620\n",
            "Epoch 83/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4800 - auc: 0.8414 - val_loss: 0.4526 - val_auc: 0.8624\n",
            "Epoch 84/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4788 - auc: 0.8392 - val_loss: 0.4517 - val_auc: 0.8649\n",
            "Epoch 85/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4762 - auc: 0.8397 - val_loss: 0.4487 - val_auc: 0.8644\n",
            "Epoch 86/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4746 - auc: 0.8426 - val_loss: 0.4473 - val_auc: 0.8681\n",
            "Epoch 87/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4729 - auc: 0.8417 - val_loss: 0.4474 - val_auc: 0.8629\n",
            "Epoch 88/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4714 - auc: 0.8441 - val_loss: 0.4440 - val_auc: 0.8692\n",
            "Epoch 89/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4707 - auc: 0.8427 - val_loss: 0.4443 - val_auc: 0.8646\n",
            "Epoch 90/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4687 - auc: 0.8434 - val_loss: 0.4419 - val_auc: 0.8707\n",
            "Epoch 91/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4676 - auc: 0.8441 - val_loss: 0.4422 - val_auc: 0.8668\n",
            "Epoch 92/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4666 - auc: 0.8454 - val_loss: 0.4390 - val_auc: 0.8677\n",
            "Epoch 93/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4660 - auc: 0.8456 - val_loss: 0.4366 - val_auc: 0.8653\n",
            "Epoch 94/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4642 - auc: 0.8472 - val_loss: 0.4359 - val_auc: 0.8683\n",
            "Epoch 95/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4635 - auc: 0.8454 - val_loss: 0.4337 - val_auc: 0.8720\n",
            "Epoch 96/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4617 - auc: 0.8504 - val_loss: 0.4340 - val_auc: 0.8688\n",
            "Epoch 97/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4609 - auc: 0.8478 - val_loss: 0.4322 - val_auc: 0.8703\n",
            "Epoch 98/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4595 - auc: 0.8485 - val_loss: 0.4306 - val_auc: 0.8679\n",
            "Epoch 99/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4584 - auc: 0.8500 - val_loss: 0.4303 - val_auc: 0.8652\n",
            "Epoch 100/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4578 - auc: 0.8487 - val_loss: 0.4295 - val_auc: 0.8667\n",
            "Epoch 101/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4562 - auc: 0.8493 - val_loss: 0.4270 - val_auc: 0.8710\n",
            "Epoch 102/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4564 - auc: 0.8518 - val_loss: 0.4258 - val_auc: 0.8665\n",
            "Epoch 103/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4552 - auc: 0.8496 - val_loss: 0.4248 - val_auc: 0.8723\n",
            "Epoch 104/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4538 - auc: 0.8516 - val_loss: 0.4256 - val_auc: 0.8692\n",
            "Epoch 105/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4530 - auc: 0.8539 - val_loss: 0.4223 - val_auc: 0.8653\n",
            "Epoch 106/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4522 - auc: 0.8526 - val_loss: 0.4244 - val_auc: 0.8693\n",
            "Epoch 107/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4514 - auc: 0.8514 - val_loss: 0.4196 - val_auc: 0.8710\n",
            "Epoch 108/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4496 - auc: 0.8523 - val_loss: 0.4196 - val_auc: 0.8694\n",
            "Epoch 109/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4502 - auc: 0.8546 - val_loss: 0.4194 - val_auc: 0.8690\n",
            "Epoch 110/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4485 - auc: 0.8514 - val_loss: 0.4173 - val_auc: 0.8723\n",
            "Epoch 111/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4474 - auc: 0.8532 - val_loss: 0.4158 - val_auc: 0.8707\n",
            "Epoch 112/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4467 - auc: 0.8520 - val_loss: 0.4153 - val_auc: 0.8716\n",
            "Epoch 113/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4453 - auc: 0.8555 - val_loss: 0.4152 - val_auc: 0.8738\n",
            "Epoch 114/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4452 - auc: 0.8524 - val_loss: 0.4146 - val_auc: 0.8681\n",
            "Epoch 115/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4436 - auc: 0.8568 - val_loss: 0.4135 - val_auc: 0.8720\n",
            "Epoch 116/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4428 - auc: 0.8555 - val_loss: 0.4111 - val_auc: 0.8750\n",
            "Epoch 117/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4418 - auc: 0.8549 - val_loss: 0.4116 - val_auc: 0.8690\n",
            "Epoch 118/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4433 - auc: 0.8526 - val_loss: 0.4112 - val_auc: 0.8715\n",
            "Epoch 119/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4416 - auc: 0.8549 - val_loss: 0.4103 - val_auc: 0.8718\n",
            "Epoch 120/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4392 - auc: 0.8564 - val_loss: 0.4083 - val_auc: 0.8749\n",
            "Epoch 121/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4401 - auc: 0.8558 - val_loss: 0.4083 - val_auc: 0.8711\n",
            "Epoch 122/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4413 - auc: 0.8560 - val_loss: 0.4063 - val_auc: 0.8716\n",
            "Epoch 123/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4410 - auc: 0.8592 - val_loss: 0.4085 - val_auc: 0.8744\n",
            "Epoch 124/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4386 - auc: 0.8575 - val_loss: 0.4048 - val_auc: 0.8755\n",
            "Epoch 125/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4366 - auc: 0.8589 - val_loss: 0.4056 - val_auc: 0.8745\n",
            "Epoch 126/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4372 - auc: 0.8588 - val_loss: 0.4037 - val_auc: 0.8725\n",
            "Epoch 127/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4350 - auc: 0.8575 - val_loss: 0.4049 - val_auc: 0.8748\n",
            "Epoch 128/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4343 - auc: 0.8585 - val_loss: 0.4028 - val_auc: 0.8756\n",
            "Epoch 129/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4338 - auc: 0.8590 - val_loss: 0.4025 - val_auc: 0.8732\n",
            "Epoch 130/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4341 - auc: 0.8586 - val_loss: 0.4026 - val_auc: 0.8738\n",
            "Epoch 131/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4325 - auc: 0.8582 - val_loss: 0.3997 - val_auc: 0.8755\n",
            "Epoch 132/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4340 - auc: 0.8562 - val_loss: 0.3991 - val_auc: 0.8756\n",
            "Epoch 133/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4326 - auc: 0.8598 - val_loss: 0.3997 - val_auc: 0.8792\n",
            "Epoch 134/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4321 - auc: 0.8593 - val_loss: 0.3988 - val_auc: 0.8756\n",
            "Epoch 135/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4323 - auc: 0.8599 - val_loss: 0.4007 - val_auc: 0.8747\n",
            "Epoch 136/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4311 - auc: 0.8587 - val_loss: 0.3984 - val_auc: 0.8737\n",
            "Epoch 137/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4309 - auc: 0.8582 - val_loss: 0.3992 - val_auc: 0.8740\n",
            "Epoch 138/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4293 - auc: 0.8580 - val_loss: 0.3968 - val_auc: 0.8771\n",
            "Epoch 139/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4291 - auc: 0.8586 - val_loss: 0.3970 - val_auc: 0.8764\n",
            "Epoch 140/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4291 - auc: 0.8600 - val_loss: 0.3972 - val_auc: 0.8776\n",
            "Epoch 141/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4284 - auc: 0.8581 - val_loss: 0.3974 - val_auc: 0.8773\n",
            "Epoch 142/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4291 - auc: 0.8573 - val_loss: 0.3944 - val_auc: 0.8776\n",
            "Epoch 143/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4279 - auc: 0.8592 - val_loss: 0.3944 - val_auc: 0.8771\n",
            "Epoch 144/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4282 - auc: 0.8596 - val_loss: 0.3952 - val_auc: 0.8769\n",
            "Epoch 145/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4286 - auc: 0.8605 - val_loss: 0.3929 - val_auc: 0.8786\n",
            "Epoch 146/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4273 - auc: 0.8596 - val_loss: 0.3948 - val_auc: 0.8782\n",
            "Epoch 147/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4271 - auc: 0.8587 - val_loss: 0.3939 - val_auc: 0.8766\n",
            "Epoch 148/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4268 - auc: 0.8588 - val_loss: 0.3925 - val_auc: 0.8775\n",
            "Epoch 149/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4261 - auc: 0.8580 - val_loss: 0.3924 - val_auc: 0.8779\n",
            "Epoch 150/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4253 - auc: 0.8590 - val_loss: 0.3926 - val_auc: 0.8775\n",
            "Epoch 151/600\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4256 - auc: 0.8593 - val_loss: 0.3910 - val_auc: 0.8767\n",
            "Epoch 152/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4253 - auc: 0.8594 - val_loss: 0.3937 - val_auc: 0.8789\n",
            "Epoch 153/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4253 - auc: 0.8591 - val_loss: 0.3906 - val_auc: 0.8808\n",
            "Epoch 154/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4268 - auc: 0.8602 - val_loss: 0.3904 - val_auc: 0.8775\n",
            "Epoch 155/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4261 - auc: 0.8606 - val_loss: 0.3905 - val_auc: 0.8792\n",
            "Epoch 156/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4242 - auc: 0.8596 - val_loss: 0.3902 - val_auc: 0.8769\n",
            "Epoch 157/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4237 - auc: 0.8601 - val_loss: 0.3899 - val_auc: 0.8830\n",
            "Epoch 158/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4231 - auc: 0.8610 - val_loss: 0.3884 - val_auc: 0.8773\n",
            "Epoch 159/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4231 - auc: 0.8610 - val_loss: 0.3885 - val_auc: 0.8773\n",
            "Epoch 160/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4261 - auc: 0.8582 - val_loss: 0.3876 - val_auc: 0.8779\n",
            "Epoch 161/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4240 - auc: 0.8615 - val_loss: 0.3891 - val_auc: 0.8780\n",
            "Epoch 162/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4220 - auc: 0.8602 - val_loss: 0.3872 - val_auc: 0.8783\n",
            "Epoch 163/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4223 - auc: 0.8610 - val_loss: 0.3858 - val_auc: 0.8806\n",
            "Epoch 164/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4223 - auc: 0.8625 - val_loss: 0.3877 - val_auc: 0.8780\n",
            "Epoch 165/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4234 - auc: 0.8606 - val_loss: 0.3857 - val_auc: 0.8782\n",
            "Epoch 166/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4220 - auc: 0.8613 - val_loss: 0.3858 - val_auc: 0.8830\n",
            "Epoch 167/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4219 - auc: 0.8598 - val_loss: 0.3858 - val_auc: 0.8793\n",
            "Epoch 168/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4210 - auc: 0.8608 - val_loss: 0.3861 - val_auc: 0.8782\n",
            "Epoch 169/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4204 - auc: 0.8618 - val_loss: 0.3856 - val_auc: 0.8785\n",
            "Epoch 170/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4204 - auc: 0.8604 - val_loss: 0.3863 - val_auc: 0.8775\n",
            "Epoch 171/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4211 - auc: 0.8611 - val_loss: 0.3854 - val_auc: 0.8786\n",
            "Epoch 172/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4206 - auc: 0.8616 - val_loss: 0.3845 - val_auc: 0.8845\n",
            "Epoch 173/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4198 - auc: 0.8615 - val_loss: 0.3856 - val_auc: 0.8784\n",
            "Epoch 174/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4214 - auc: 0.8615 - val_loss: 0.3833 - val_auc: 0.8795\n",
            "Epoch 175/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4201 - auc: 0.8622 - val_loss: 0.3836 - val_auc: 0.8849\n",
            "Epoch 176/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4202 - auc: 0.8625 - val_loss: 0.3855 - val_auc: 0.8783\n",
            "Epoch 177/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4209 - auc: 0.8619 - val_loss: 0.3828 - val_auc: 0.8797\n",
            "Epoch 178/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4189 - auc: 0.8607 - val_loss: 0.3844 - val_auc: 0.8798\n",
            "Epoch 179/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4208 - auc: 0.8601 - val_loss: 0.3870 - val_auc: 0.8777\n",
            "Epoch 180/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4189 - auc: 0.8631 - val_loss: 0.3828 - val_auc: 0.8820\n",
            "Epoch 181/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4216 - auc: 0.8603 - val_loss: 0.3825 - val_auc: 0.8820\n",
            "Epoch 182/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4189 - auc: 0.8622 - val_loss: 0.3817 - val_auc: 0.8813\n",
            "Epoch 183/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4184 - auc: 0.8634 - val_loss: 0.3830 - val_auc: 0.8784\n",
            "Epoch 184/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4184 - auc: 0.8621 - val_loss: 0.3822 - val_auc: 0.8866\n",
            "Epoch 185/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4173 - auc: 0.8622 - val_loss: 0.3819 - val_auc: 0.8805\n",
            "Epoch 186/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4178 - auc: 0.8636 - val_loss: 0.3812 - val_auc: 0.8868\n",
            "Epoch 187/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4186 - auc: 0.8641 - val_loss: 0.3809 - val_auc: 0.8876\n",
            "Epoch 188/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4190 - auc: 0.8604 - val_loss: 0.3818 - val_auc: 0.8823\n",
            "Epoch 189/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4175 - auc: 0.8645 - val_loss: 0.3806 - val_auc: 0.8830\n",
            "Epoch 190/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4173 - auc: 0.8625 - val_loss: 0.3825 - val_auc: 0.8867\n",
            "Epoch 191/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4181 - auc: 0.8616 - val_loss: 0.3812 - val_auc: 0.8808\n",
            "Epoch 192/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4169 - auc: 0.8621 - val_loss: 0.3814 - val_auc: 0.8821\n",
            "Epoch 193/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4171 - auc: 0.8639 - val_loss: 0.3801 - val_auc: 0.8847\n",
            "Epoch 194/600\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4164 - auc: 0.8625 - val_loss: 0.3813 - val_auc: 0.8799\n",
            "Epoch 195/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4162 - auc: 0.8626 - val_loss: 0.3798 - val_auc: 0.8816\n",
            "Epoch 196/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4177 - auc: 0.8611 - val_loss: 0.3794 - val_auc: 0.8798\n",
            "Epoch 197/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4156 - auc: 0.8630 - val_loss: 0.3813 - val_auc: 0.8864\n",
            "Epoch 198/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4168 - auc: 0.8646 - val_loss: 0.3796 - val_auc: 0.8856\n",
            "Epoch 199/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4161 - auc: 0.8644 - val_loss: 0.3793 - val_auc: 0.8827\n",
            "Epoch 200/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4182 - auc: 0.8619 - val_loss: 0.3813 - val_auc: 0.8799\n",
            "Epoch 201/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4181 - auc: 0.8623 - val_loss: 0.3808 - val_auc: 0.8793\n",
            "Epoch 202/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4161 - auc: 0.8636 - val_loss: 0.3798 - val_auc: 0.8869\n",
            "Epoch 203/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4186 - auc: 0.8614 - val_loss: 0.3808 - val_auc: 0.8866\n",
            "Epoch 204/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4156 - auc: 0.8655 - val_loss: 0.3790 - val_auc: 0.8811\n",
            "Epoch 205/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4150 - auc: 0.8659 - val_loss: 0.3826 - val_auc: 0.8821\n",
            "Epoch 206/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4155 - auc: 0.8637 - val_loss: 0.3782 - val_auc: 0.8819\n",
            "Epoch 207/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4152 - auc: 0.8650 - val_loss: 0.3799 - val_auc: 0.8823\n",
            "Epoch 208/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4177 - auc: 0.8623 - val_loss: 0.3783 - val_auc: 0.8820\n",
            "Epoch 209/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4153 - auc: 0.8644 - val_loss: 0.3804 - val_auc: 0.8866\n",
            "Epoch 210/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4147 - auc: 0.8645 - val_loss: 0.3781 - val_auc: 0.8854\n",
            "Epoch 211/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4158 - auc: 0.8632 - val_loss: 0.3786 - val_auc: 0.8806\n",
            "Epoch 212/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4146 - auc: 0.8653 - val_loss: 0.3780 - val_auc: 0.8869\n",
            "Epoch 213/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4147 - auc: 0.8634 - val_loss: 0.3781 - val_auc: 0.8849\n",
            "Epoch 214/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4152 - auc: 0.8632 - val_loss: 0.3778 - val_auc: 0.8823\n",
            "Epoch 215/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4144 - auc: 0.8655 - val_loss: 0.3793 - val_auc: 0.8808\n",
            "Epoch 216/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4180 - auc: 0.8588 - val_loss: 0.3773 - val_auc: 0.8830\n",
            "Epoch 217/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4135 - auc: 0.8643 - val_loss: 0.3799 - val_auc: 0.8877\n",
            "Epoch 218/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4142 - auc: 0.8661 - val_loss: 0.3782 - val_auc: 0.8843\n",
            "Epoch 219/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4137 - auc: 0.8656 - val_loss: 0.3786 - val_auc: 0.8811\n",
            "Epoch 220/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4140 - auc: 0.8658 - val_loss: 0.3778 - val_auc: 0.8825\n",
            "Epoch 221/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4148 - auc: 0.8662 - val_loss: 0.3787 - val_auc: 0.8809\n",
            "Epoch 222/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4138 - auc: 0.8648 - val_loss: 0.3806 - val_auc: 0.8880\n",
            "Epoch 223/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4135 - auc: 0.8672 - val_loss: 0.3780 - val_auc: 0.8819\n",
            "Epoch 224/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4128 - auc: 0.8647 - val_loss: 0.3797 - val_auc: 0.8878\n",
            "Epoch 225/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4146 - auc: 0.8660 - val_loss: 0.3774 - val_auc: 0.8812\n",
            "Epoch 226/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4125 - auc: 0.8664 - val_loss: 0.3786 - val_auc: 0.8830\n",
            "Epoch 227/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4133 - auc: 0.8648 - val_loss: 0.3781 - val_auc: 0.8864\n",
            "Epoch 228/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4161 - auc: 0.8644 - val_loss: 0.3772 - val_auc: 0.8823\n",
            "Epoch 229/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4140 - auc: 0.8633 - val_loss: 0.3773 - val_auc: 0.8860\n",
            "Epoch 230/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4126 - auc: 0.8658 - val_loss: 0.3767 - val_auc: 0.8836\n",
            "Epoch 231/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4124 - auc: 0.8666 - val_loss: 0.3774 - val_auc: 0.8866\n",
            "Epoch 232/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4130 - auc: 0.8645 - val_loss: 0.3793 - val_auc: 0.8845\n",
            "Epoch 233/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4122 - auc: 0.8661 - val_loss: 0.3774 - val_auc: 0.8812\n",
            "Epoch 234/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4134 - auc: 0.8696 - val_loss: 0.3771 - val_auc: 0.8875\n",
            "Epoch 235/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4117 - auc: 0.8656 - val_loss: 0.3781 - val_auc: 0.8810\n",
            "Epoch 236/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4125 - auc: 0.8668 - val_loss: 0.3766 - val_auc: 0.8859\n",
            "Epoch 237/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4128 - auc: 0.8660 - val_loss: 0.3771 - val_auc: 0.8877\n",
            "Epoch 238/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4118 - auc: 0.8655 - val_loss: 0.3773 - val_auc: 0.8873\n",
            "Epoch 239/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4133 - auc: 0.8635 - val_loss: 0.3775 - val_auc: 0.8836\n",
            "Epoch 240/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4121 - auc: 0.8660 - val_loss: 0.3777 - val_auc: 0.8877\n",
            "Epoch 241/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4121 - auc: 0.8658 - val_loss: 0.3789 - val_auc: 0.8847\n",
            "Epoch 242/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4120 - auc: 0.8640 - val_loss: 0.3775 - val_auc: 0.8837\n",
            "Epoch 243/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4122 - auc: 0.8673 - val_loss: 0.3779 - val_auc: 0.8840\n",
            "Epoch 244/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4130 - auc: 0.8649 - val_loss: 0.3780 - val_auc: 0.8864\n",
            "Epoch 245/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4116 - auc: 0.8661 - val_loss: 0.3780 - val_auc: 0.8827\n",
            "Epoch 246/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4111 - auc: 0.8659 - val_loss: 0.3768 - val_auc: 0.8839\n",
            "Epoch 247/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4114 - auc: 0.8672 - val_loss: 0.3765 - val_auc: 0.8865\n",
            "Epoch 248/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4117 - auc: 0.8650 - val_loss: 0.3786 - val_auc: 0.8873\n",
            "Epoch 249/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4122 - auc: 0.8642 - val_loss: 0.3772 - val_auc: 0.8845\n",
            "Epoch 250/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4113 - auc: 0.8663 - val_loss: 0.3778 - val_auc: 0.8877\n",
            "Epoch 251/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4106 - auc: 0.8668 - val_loss: 0.3770 - val_auc: 0.8854\n",
            "Epoch 252/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4122 - auc: 0.8647 - val_loss: 0.3788 - val_auc: 0.8874\n",
            "Epoch 253/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4111 - auc: 0.8662 - val_loss: 0.3763 - val_auc: 0.8830\n",
            "Epoch 254/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4113 - auc: 0.8674 - val_loss: 0.3772 - val_auc: 0.8821\n",
            "Epoch 255/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4106 - auc: 0.8651 - val_loss: 0.3765 - val_auc: 0.8871\n",
            "Epoch 256/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4117 - auc: 0.8641 - val_loss: 0.3772 - val_auc: 0.8858\n",
            "Epoch 257/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4104 - auc: 0.8667 - val_loss: 0.3773 - val_auc: 0.8856\n",
            "Epoch 258/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4108 - auc: 0.8675 - val_loss: 0.3766 - val_auc: 0.8862\n",
            "Epoch 259/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4107 - auc: 0.8662 - val_loss: 0.3767 - val_auc: 0.8867\n",
            "Epoch 260/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4113 - auc: 0.8674 - val_loss: 0.3777 - val_auc: 0.8851\n",
            "Epoch 261/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4110 - auc: 0.8653 - val_loss: 0.3763 - val_auc: 0.8830\n",
            "Epoch 262/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4145 - auc: 0.8681 - val_loss: 0.3786 - val_auc: 0.8854\n",
            "Epoch 263/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4130 - auc: 0.8662 - val_loss: 0.3762 - val_auc: 0.8835\n",
            "Epoch 264/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4107 - auc: 0.8671 - val_loss: 0.3763 - val_auc: 0.8835\n",
            "Epoch 265/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4105 - auc: 0.8662 - val_loss: 0.3762 - val_auc: 0.8849\n",
            "Epoch 266/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4106 - auc: 0.8671 - val_loss: 0.3780 - val_auc: 0.8878\n",
            "Epoch 267/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4098 - auc: 0.8669 - val_loss: 0.3779 - val_auc: 0.8837\n",
            "Epoch 268/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4102 - auc: 0.8669 - val_loss: 0.3770 - val_auc: 0.8827\n",
            "Epoch 269/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4113 - auc: 0.8673 - val_loss: 0.3769 - val_auc: 0.8886\n",
            "Epoch 270/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4113 - auc: 0.8668 - val_loss: 0.3766 - val_auc: 0.8837\n",
            "Epoch 271/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4096 - auc: 0.8680 - val_loss: 0.3771 - val_auc: 0.8831\n",
            "Epoch 272/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4094 - auc: 0.8672 - val_loss: 0.3796 - val_auc: 0.8870\n",
            "Epoch 273/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4093 - auc: 0.8678 - val_loss: 0.3768 - val_auc: 0.8888\n",
            "Epoch 274/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4098 - auc: 0.8687 - val_loss: 0.3782 - val_auc: 0.8853\n",
            "Epoch 275/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4114 - auc: 0.8679 - val_loss: 0.3776 - val_auc: 0.8832\n",
            "Epoch 276/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4106 - auc: 0.8667 - val_loss: 0.3777 - val_auc: 0.8880\n",
            "Epoch 277/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4101 - auc: 0.8676 - val_loss: 0.3773 - val_auc: 0.8853\n",
            "Epoch 278/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4096 - auc: 0.8691 - val_loss: 0.3769 - val_auc: 0.8845\n",
            "Epoch 279/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4102 - auc: 0.8668 - val_loss: 0.3780 - val_auc: 0.8879\n",
            "Epoch 280/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4091 - auc: 0.8681 - val_loss: 0.3774 - val_auc: 0.8836\n",
            "Epoch 281/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4095 - auc: 0.8682 - val_loss: 0.3776 - val_auc: 0.8856\n",
            "Epoch 282/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4096 - auc: 0.8672 - val_loss: 0.3773 - val_auc: 0.8857\n",
            "Epoch 283/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4096 - auc: 0.8686 - val_loss: 0.3772 - val_auc: 0.8892\n",
            "Epoch 284/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4098 - auc: 0.8665 - val_loss: 0.3780 - val_auc: 0.8866\n",
            "Epoch 285/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4108 - auc: 0.8674 - val_loss: 0.3805 - val_auc: 0.8893\n",
            "Epoch 286/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4094 - auc: 0.8691 - val_loss: 0.3768 - val_auc: 0.8873\n",
            "Epoch 287/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4098 - auc: 0.8684 - val_loss: 0.3777 - val_auc: 0.8862\n",
            "Epoch 288/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4094 - auc: 0.8668 - val_loss: 0.3765 - val_auc: 0.8869\n",
            "Epoch 289/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4086 - auc: 0.8681 - val_loss: 0.3775 - val_auc: 0.8869\n",
            "Epoch 290/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4091 - auc: 0.8663 - val_loss: 0.3806 - val_auc: 0.8863\n",
            "Epoch 291/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4098 - auc: 0.8677 - val_loss: 0.3790 - val_auc: 0.8901\n",
            "Epoch 292/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4126 - auc: 0.8663 - val_loss: 0.3778 - val_auc: 0.8862\n",
            "Epoch 293/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4152 - auc: 0.8638 - val_loss: 0.3772 - val_auc: 0.8877\n",
            "Epoch 294/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4106 - auc: 0.8673 - val_loss: 0.3780 - val_auc: 0.8893\n",
            "Epoch 295/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4092 - auc: 0.8669 - val_loss: 0.3769 - val_auc: 0.8871\n",
            "Epoch 296/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4080 - auc: 0.8684 - val_loss: 0.3793 - val_auc: 0.8900\n",
            "Epoch 297/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4086 - auc: 0.8670 - val_loss: 0.3775 - val_auc: 0.8901\n",
            "Epoch 298/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4083 - auc: 0.8695 - val_loss: 0.3773 - val_auc: 0.8902\n",
            "Epoch 299/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4078 - auc: 0.8699 - val_loss: 0.3800 - val_auc: 0.8873\n",
            "Epoch 300/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4081 - auc: 0.8699 - val_loss: 0.3774 - val_auc: 0.8901\n",
            "Epoch 301/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4119 - auc: 0.8694 - val_loss: 0.3776 - val_auc: 0.8884\n",
            "Epoch 302/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4107 - auc: 0.8671 - val_loss: 0.3798 - val_auc: 0.8899\n",
            "Epoch 303/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4087 - auc: 0.8686 - val_loss: 0.3777 - val_auc: 0.8869\n",
            "Epoch 304/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4076 - auc: 0.8696 - val_loss: 0.3773 - val_auc: 0.8888\n",
            "Epoch 305/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4078 - auc: 0.8704 - val_loss: 0.3793 - val_auc: 0.8860\n",
            "Epoch 306/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4080 - auc: 0.8677 - val_loss: 0.3772 - val_auc: 0.8877\n",
            "Epoch 307/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4091 - auc: 0.8668 - val_loss: 0.3788 - val_auc: 0.8884\n",
            "Epoch 308/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4154 - auc: 0.8657 - val_loss: 0.3786 - val_auc: 0.8884\n",
            "Epoch 309/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4099 - auc: 0.8673 - val_loss: 0.3798 - val_auc: 0.8875\n",
            "Epoch 310/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4094 - auc: 0.8697 - val_loss: 0.3779 - val_auc: 0.8879\n",
            "Epoch 311/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4072 - auc: 0.8679 - val_loss: 0.3804 - val_auc: 0.8873\n",
            "Epoch 312/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4081 - auc: 0.8682 - val_loss: 0.3789 - val_auc: 0.8873\n",
            "Epoch 313/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4084 - auc: 0.8680 - val_loss: 0.3790 - val_auc: 0.8861\n",
            "Epoch 314/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4103 - auc: 0.8677 - val_loss: 0.3781 - val_auc: 0.8882\n",
            "Epoch 315/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4085 - auc: 0.8665 - val_loss: 0.3790 - val_auc: 0.8873\n",
            "Epoch 316/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4071 - auc: 0.8710 - val_loss: 0.3777 - val_auc: 0.8842\n",
            "Epoch 317/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4079 - auc: 0.8684 - val_loss: 0.3787 - val_auc: 0.8903\n",
            "Epoch 318/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4080 - auc: 0.8679 - val_loss: 0.3781 - val_auc: 0.8884\n",
            "Epoch 319/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4069 - auc: 0.8693 - val_loss: 0.3778 - val_auc: 0.8902\n",
            "Epoch 320/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4077 - auc: 0.8690 - val_loss: 0.3798 - val_auc: 0.8863\n",
            "Epoch 321/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4068 - auc: 0.8705 - val_loss: 0.3780 - val_auc: 0.8862\n",
            "Epoch 322/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4071 - auc: 0.8689 - val_loss: 0.3779 - val_auc: 0.8871\n",
            "Epoch 323/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4108 - auc: 0.8653 - val_loss: 0.3784 - val_auc: 0.8906\n",
            "Epoch 324/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4075 - auc: 0.8682 - val_loss: 0.3784 - val_auc: 0.8880\n",
            "Epoch 325/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4082 - auc: 0.8665 - val_loss: 0.3784 - val_auc: 0.8876\n",
            "Epoch 326/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4073 - auc: 0.8687 - val_loss: 0.3788 - val_auc: 0.8911\n",
            "Epoch 327/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4073 - auc: 0.8684 - val_loss: 0.3782 - val_auc: 0.8900\n",
            "Epoch 328/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4068 - auc: 0.8693 - val_loss: 0.3782 - val_auc: 0.8888\n",
            "Epoch 329/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4081 - auc: 0.8696 - val_loss: 0.3784 - val_auc: 0.8899\n",
            "Epoch 330/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4074 - auc: 0.8693 - val_loss: 0.3793 - val_auc: 0.8900\n",
            "Epoch 331/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4070 - auc: 0.8693 - val_loss: 0.3784 - val_auc: 0.8895\n",
            "Epoch 332/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4063 - auc: 0.8700 - val_loss: 0.3796 - val_auc: 0.8902\n",
            "Epoch 333/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4069 - auc: 0.8690 - val_loss: 0.3784 - val_auc: 0.8909\n",
            "Epoch 334/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4075 - auc: 0.8692 - val_loss: 0.3788 - val_auc: 0.8888\n",
            "Epoch 335/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4069 - auc: 0.8692 - val_loss: 0.3790 - val_auc: 0.8885\n",
            "Epoch 336/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4065 - auc: 0.8684 - val_loss: 0.3790 - val_auc: 0.8875\n",
            "Epoch 337/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4088 - auc: 0.8672 - val_loss: 0.3783 - val_auc: 0.8867\n",
            "Epoch 338/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4072 - auc: 0.8692 - val_loss: 0.3787 - val_auc: 0.8880\n",
            "Epoch 339/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4102 - auc: 0.8669 - val_loss: 0.3781 - val_auc: 0.8904\n",
            "Epoch 340/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4076 - auc: 0.8709 - val_loss: 0.3785 - val_auc: 0.8884\n",
            "Epoch 341/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4062 - auc: 0.8686 - val_loss: 0.3783 - val_auc: 0.8872\n",
            "Epoch 342/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4070 - auc: 0.8695 - val_loss: 0.3791 - val_auc: 0.8867\n",
            "Epoch 343/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4093 - auc: 0.8683 - val_loss: 0.3796 - val_auc: 0.8908\n",
            "Epoch 344/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4079 - auc: 0.8700 - val_loss: 0.3782 - val_auc: 0.8897\n",
            "Epoch 345/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4062 - auc: 0.8694 - val_loss: 0.3795 - val_auc: 0.8888\n",
            "Epoch 346/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4066 - auc: 0.8702 - val_loss: 0.3792 - val_auc: 0.8882\n",
            "Epoch 347/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4073 - auc: 0.8684 - val_loss: 0.3785 - val_auc: 0.8866\n",
            "Epoch 348/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4062 - auc: 0.8702 - val_loss: 0.3799 - val_auc: 0.8898\n",
            "Epoch 349/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4066 - auc: 0.8692 - val_loss: 0.3791 - val_auc: 0.8871\n",
            "Epoch 350/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4067 - auc: 0.8713 - val_loss: 0.3800 - val_auc: 0.8883\n",
            "Epoch 351/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4069 - auc: 0.8702 - val_loss: 0.3803 - val_auc: 0.8885\n",
            "Epoch 352/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4063 - auc: 0.8698 - val_loss: 0.3798 - val_auc: 0.8886\n",
            "Epoch 353/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4061 - auc: 0.8700 - val_loss: 0.3805 - val_auc: 0.8880\n",
            "Epoch 354/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4064 - auc: 0.8706 - val_loss: 0.3804 - val_auc: 0.8889\n",
            "Epoch 355/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4064 - auc: 0.8703 - val_loss: 0.3801 - val_auc: 0.8896\n",
            "Epoch 356/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4064 - auc: 0.8709 - val_loss: 0.3791 - val_auc: 0.8893\n",
            "Epoch 357/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4060 - auc: 0.8704 - val_loss: 0.3798 - val_auc: 0.8876\n",
            "Epoch 358/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4058 - auc: 0.8699 - val_loss: 0.3788 - val_auc: 0.8871\n",
            "Epoch 359/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4074 - auc: 0.8690 - val_loss: 0.3793 - val_auc: 0.8884\n",
            "Epoch 360/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4075 - auc: 0.8659 - val_loss: 0.3789 - val_auc: 0.8880\n",
            "Epoch 361/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4064 - auc: 0.8701 - val_loss: 0.3793 - val_auc: 0.8877\n",
            "Epoch 362/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4064 - auc: 0.8686 - val_loss: 0.3788 - val_auc: 0.8876\n",
            "Epoch 363/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4062 - auc: 0.8709 - val_loss: 0.3799 - val_auc: 0.8890\n",
            "Epoch 364/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4092 - auc: 0.8705 - val_loss: 0.3791 - val_auc: 0.8893\n",
            "Epoch 365/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4066 - auc: 0.8721 - val_loss: 0.3811 - val_auc: 0.8899\n",
            "Epoch 366/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4071 - auc: 0.8695 - val_loss: 0.3799 - val_auc: 0.8890\n",
            "Epoch 367/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4053 - auc: 0.8681 - val_loss: 0.3794 - val_auc: 0.8899\n",
            "Epoch 368/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4081 - auc: 0.8699 - val_loss: 0.3819 - val_auc: 0.8879\n",
            "Epoch 369/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4091 - auc: 0.8717 - val_loss: 0.3797 - val_auc: 0.8882\n",
            "Epoch 370/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4083 - auc: 0.8702 - val_loss: 0.3801 - val_auc: 0.8868\n",
            "Epoch 371/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4066 - auc: 0.8683 - val_loss: 0.3796 - val_auc: 0.8857\n",
            "Epoch 372/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4055 - auc: 0.8707 - val_loss: 0.3804 - val_auc: 0.8894\n",
            "Epoch 373/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4070 - auc: 0.8675 - val_loss: 0.3816 - val_auc: 0.8862\n",
            "Epoch 374/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4075 - auc: 0.8686 - val_loss: 0.3799 - val_auc: 0.8872\n",
            "Epoch 375/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4056 - auc: 0.8710 - val_loss: 0.3792 - val_auc: 0.8897\n",
            "Epoch 376/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4061 - auc: 0.8696 - val_loss: 0.3807 - val_auc: 0.8899\n",
            "Epoch 377/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4056 - auc: 0.8699 - val_loss: 0.3812 - val_auc: 0.8886\n",
            "Epoch 378/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4060 - auc: 0.8701 - val_loss: 0.3800 - val_auc: 0.8886\n",
            "Epoch 379/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4054 - auc: 0.8705 - val_loss: 0.3801 - val_auc: 0.8878\n",
            "Epoch 380/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4066 - auc: 0.8682 - val_loss: 0.3812 - val_auc: 0.8890\n",
            "Epoch 381/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4075 - auc: 0.8676 - val_loss: 0.3798 - val_auc: 0.8851\n",
            "Epoch 382/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4055 - auc: 0.8704 - val_loss: 0.3794 - val_auc: 0.8886\n",
            "Epoch 383/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4074 - auc: 0.8692 - val_loss: 0.3798 - val_auc: 0.8871\n",
            "Epoch 384/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4053 - auc: 0.8700 - val_loss: 0.3801 - val_auc: 0.8875\n",
            "Epoch 385/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4053 - auc: 0.8700 - val_loss: 0.3806 - val_auc: 0.8904\n",
            "Epoch 386/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4053 - auc: 0.8711 - val_loss: 0.3804 - val_auc: 0.8867\n",
            "Epoch 387/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4053 - auc: 0.8700 - val_loss: 0.3803 - val_auc: 0.8843\n",
            "Epoch 388/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4051 - auc: 0.8702 - val_loss: 0.3802 - val_auc: 0.8877\n",
            "Epoch 389/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4059 - auc: 0.8688 - val_loss: 0.3810 - val_auc: 0.8897\n",
            "Epoch 390/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4060 - auc: 0.8696 - val_loss: 0.3809 - val_auc: 0.8869\n",
            "Epoch 391/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4061 - auc: 0.8694 - val_loss: 0.3806 - val_auc: 0.8871\n",
            "Epoch 392/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4062 - auc: 0.8705 - val_loss: 0.3803 - val_auc: 0.8854\n",
            "Epoch 393/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4053 - auc: 0.8706 - val_loss: 0.3802 - val_auc: 0.8860\n",
            "Epoch 394/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4062 - auc: 0.8688 - val_loss: 0.3813 - val_auc: 0.8888\n",
            "Epoch 395/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4049 - auc: 0.8703 - val_loss: 0.3805 - val_auc: 0.8889\n",
            "Epoch 396/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4052 - auc: 0.8702 - val_loss: 0.3808 - val_auc: 0.8865\n",
            "Epoch 397/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4101 - auc: 0.8681 - val_loss: 0.3805 - val_auc: 0.8849\n",
            "Epoch 398/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4052 - auc: 0.8720 - val_loss: 0.3804 - val_auc: 0.8866\n",
            "Epoch 399/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4051 - auc: 0.8706 - val_loss: 0.3807 - val_auc: 0.8879\n",
            "Epoch 400/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4053 - auc: 0.8696 - val_loss: 0.3800 - val_auc: 0.8880\n",
            "Epoch 401/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4050 - auc: 0.8701 - val_loss: 0.3808 - val_auc: 0.8871\n",
            "Epoch 402/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4048 - auc: 0.8701 - val_loss: 0.3811 - val_auc: 0.8869\n",
            "Epoch 403/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4052 - auc: 0.8701 - val_loss: 0.3803 - val_auc: 0.8888\n",
            "Epoch 404/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4057 - auc: 0.8687 - val_loss: 0.3804 - val_auc: 0.8886\n",
            "Epoch 405/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4067 - auc: 0.8679 - val_loss: 0.3803 - val_auc: 0.8893\n",
            "Epoch 406/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4043 - auc: 0.8709 - val_loss: 0.3812 - val_auc: 0.8873\n",
            "Epoch 407/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4059 - auc: 0.8683 - val_loss: 0.3810 - val_auc: 0.8880\n",
            "Epoch 408/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4072 - auc: 0.8690 - val_loss: 0.3805 - val_auc: 0.8854\n",
            "Epoch 409/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4059 - auc: 0.8707 - val_loss: 0.3826 - val_auc: 0.8882\n",
            "Epoch 410/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4050 - auc: 0.8698 - val_loss: 0.3814 - val_auc: 0.8865\n",
            "Epoch 411/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4051 - auc: 0.8709 - val_loss: 0.3803 - val_auc: 0.8879\n",
            "Epoch 412/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4062 - auc: 0.8705 - val_loss: 0.3803 - val_auc: 0.8888\n",
            "Epoch 413/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4051 - auc: 0.8696 - val_loss: 0.3817 - val_auc: 0.8879\n",
            "Epoch 414/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4042 - auc: 0.8701 - val_loss: 0.3804 - val_auc: 0.8891\n",
            "Epoch 415/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4052 - auc: 0.8705 - val_loss: 0.3807 - val_auc: 0.8878\n",
            "Epoch 416/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4043 - auc: 0.8695 - val_loss: 0.3811 - val_auc: 0.8875\n",
            "Epoch 417/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4045 - auc: 0.8698 - val_loss: 0.3809 - val_auc: 0.8899\n",
            "Epoch 418/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4062 - auc: 0.8686 - val_loss: 0.3847 - val_auc: 0.8886\n",
            "Epoch 419/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4056 - auc: 0.8708 - val_loss: 0.3813 - val_auc: 0.8852\n",
            "Epoch 420/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4055 - auc: 0.8698 - val_loss: 0.3807 - val_auc: 0.8884\n",
            "Epoch 421/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4058 - auc: 0.8698 - val_loss: 0.3809 - val_auc: 0.8898\n",
            "Epoch 422/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4041 - auc: 0.8694 - val_loss: 0.3815 - val_auc: 0.8851\n",
            "Epoch 423/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4044 - auc: 0.8703 - val_loss: 0.3820 - val_auc: 0.8869\n",
            "Epoch 424/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4056 - auc: 0.8682 - val_loss: 0.3817 - val_auc: 0.8881\n",
            "Epoch 425/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4045 - auc: 0.8695 - val_loss: 0.3816 - val_auc: 0.8880\n",
            "Epoch 426/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4080 - auc: 0.8675 - val_loss: 0.3809 - val_auc: 0.8869\n",
            "Epoch 427/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4061 - auc: 0.8696 - val_loss: 0.3819 - val_auc: 0.8875\n",
            "Epoch 428/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4044 - auc: 0.8697 - val_loss: 0.3813 - val_auc: 0.8893\n",
            "Epoch 429/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4044 - auc: 0.8714 - val_loss: 0.3822 - val_auc: 0.8850\n",
            "Epoch 430/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4045 - auc: 0.8693 - val_loss: 0.3808 - val_auc: 0.8854\n",
            "Epoch 431/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4049 - auc: 0.8689 - val_loss: 0.3820 - val_auc: 0.8875\n",
            "Epoch 432/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4039 - auc: 0.8706 - val_loss: 0.3812 - val_auc: 0.8907\n",
            "Epoch 433/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4054 - auc: 0.8700 - val_loss: 0.3814 - val_auc: 0.8854\n",
            "Epoch 434/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4047 - auc: 0.8695 - val_loss: 0.3822 - val_auc: 0.8858\n",
            "Epoch 435/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4041 - auc: 0.8717 - val_loss: 0.3808 - val_auc: 0.8913\n",
            "Epoch 436/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4052 - auc: 0.8685 - val_loss: 0.3811 - val_auc: 0.8895\n",
            "Epoch 437/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4050 - auc: 0.8694 - val_loss: 0.3828 - val_auc: 0.8865\n",
            "Epoch 438/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4043 - auc: 0.8692 - val_loss: 0.3813 - val_auc: 0.8893\n",
            "Epoch 439/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4070 - auc: 0.8692 - val_loss: 0.3817 - val_auc: 0.8857\n",
            "Epoch 440/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4038 - auc: 0.8703 - val_loss: 0.3813 - val_auc: 0.8895\n",
            "Epoch 441/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4043 - auc: 0.8700 - val_loss: 0.3814 - val_auc: 0.8909\n",
            "Epoch 442/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4054 - auc: 0.8685 - val_loss: 0.3815 - val_auc: 0.8896\n",
            "Epoch 443/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4032 - auc: 0.8704 - val_loss: 0.3814 - val_auc: 0.8899\n",
            "Epoch 444/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4043 - auc: 0.8695 - val_loss: 0.3822 - val_auc: 0.8873\n",
            "Epoch 445/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4038 - auc: 0.8704 - val_loss: 0.3813 - val_auc: 0.8894\n",
            "Epoch 446/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4045 - auc: 0.8682 - val_loss: 0.3812 - val_auc: 0.8910\n",
            "Epoch 447/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4053 - auc: 0.8706 - val_loss: 0.3814 - val_auc: 0.8854\n",
            "Epoch 448/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4040 - auc: 0.8705 - val_loss: 0.3811 - val_auc: 0.8918\n",
            "Epoch 449/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4041 - auc: 0.8711 - val_loss: 0.3818 - val_auc: 0.8880\n",
            "Epoch 450/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4045 - auc: 0.8699 - val_loss: 0.3819 - val_auc: 0.8893\n",
            "Epoch 451/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4051 - auc: 0.8707 - val_loss: 0.3812 - val_auc: 0.8857\n",
            "Epoch 452/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4038 - auc: 0.8706 - val_loss: 0.3826 - val_auc: 0.8872\n",
            "Epoch 453/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4034 - auc: 0.8709 - val_loss: 0.3823 - val_auc: 0.8878\n",
            "Epoch 454/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4035 - auc: 0.8704 - val_loss: 0.3815 - val_auc: 0.8856\n",
            "Epoch 455/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4037 - auc: 0.8698 - val_loss: 0.3814 - val_auc: 0.8871\n",
            "Epoch 456/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4047 - auc: 0.8697 - val_loss: 0.3819 - val_auc: 0.8897\n",
            "Epoch 457/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4036 - auc: 0.8708 - val_loss: 0.3820 - val_auc: 0.8900\n",
            "Epoch 458/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4040 - auc: 0.8688 - val_loss: 0.3815 - val_auc: 0.8880\n",
            "Epoch 459/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4055 - auc: 0.8702 - val_loss: 0.3821 - val_auc: 0.8895\n",
            "Epoch 460/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4034 - auc: 0.8706 - val_loss: 0.3819 - val_auc: 0.8908\n",
            "Epoch 461/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4032 - auc: 0.8697 - val_loss: 0.3819 - val_auc: 0.8914\n",
            "Epoch 462/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4050 - auc: 0.8686 - val_loss: 0.3815 - val_auc: 0.8875\n",
            "Epoch 463/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4034 - auc: 0.8704 - val_loss: 0.3822 - val_auc: 0.8901\n",
            "Epoch 464/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4036 - auc: 0.8706 - val_loss: 0.3820 - val_auc: 0.8897\n",
            "Epoch 465/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4041 - auc: 0.8699 - val_loss: 0.3820 - val_auc: 0.8908\n",
            "Epoch 466/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4030 - auc: 0.8712 - val_loss: 0.3819 - val_auc: 0.8865\n",
            "Epoch 467/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4044 - auc: 0.8692 - val_loss: 0.3824 - val_auc: 0.8882\n",
            "Epoch 468/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4038 - auc: 0.8705 - val_loss: 0.3824 - val_auc: 0.8895\n",
            "Epoch 469/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4033 - auc: 0.8712 - val_loss: 0.3822 - val_auc: 0.8899\n",
            "Epoch 470/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4038 - auc: 0.8698 - val_loss: 0.3818 - val_auc: 0.8919\n",
            "Epoch 471/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4039 - auc: 0.8690 - val_loss: 0.3820 - val_auc: 0.8908\n",
            "Epoch 472/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4032 - auc: 0.8707 - val_loss: 0.3819 - val_auc: 0.8877\n",
            "Epoch 473/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4038 - auc: 0.8705 - val_loss: 0.3818 - val_auc: 0.8881\n",
            "Epoch 474/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4082 - auc: 0.8673 - val_loss: 0.3821 - val_auc: 0.8860\n",
            "Epoch 475/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4036 - auc: 0.8698 - val_loss: 0.3823 - val_auc: 0.8865\n",
            "Epoch 476/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4037 - auc: 0.8696 - val_loss: 0.3822 - val_auc: 0.8874\n",
            "Epoch 477/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4037 - auc: 0.8700 - val_loss: 0.3822 - val_auc: 0.8862\n",
            "Epoch 478/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4045 - auc: 0.8707 - val_loss: 0.3823 - val_auc: 0.8910\n",
            "Epoch 479/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4045 - auc: 0.8701 - val_loss: 0.3826 - val_auc: 0.8893\n",
            "Epoch 480/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4036 - auc: 0.8695 - val_loss: 0.3831 - val_auc: 0.8855\n",
            "Epoch 481/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4047 - auc: 0.8702 - val_loss: 0.3827 - val_auc: 0.8906\n",
            "Epoch 482/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4051 - auc: 0.8707 - val_loss: 0.3827 - val_auc: 0.8908\n",
            "Epoch 483/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4041 - auc: 0.8719 - val_loss: 0.3831 - val_auc: 0.8893\n",
            "Epoch 484/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4041 - auc: 0.8704 - val_loss: 0.3848 - val_auc: 0.8897\n",
            "Epoch 485/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4040 - auc: 0.8711 - val_loss: 0.3828 - val_auc: 0.8895\n",
            "Epoch 486/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4045 - auc: 0.8684 - val_loss: 0.3829 - val_auc: 0.8896\n",
            "Epoch 487/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4032 - auc: 0.8700 - val_loss: 0.3834 - val_auc: 0.8856\n",
            "Epoch 488/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4038 - auc: 0.8710 - val_loss: 0.3831 - val_auc: 0.8861\n",
            "Epoch 489/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4041 - auc: 0.8697 - val_loss: 0.3830 - val_auc: 0.8887\n",
            "Epoch 490/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4039 - auc: 0.8694 - val_loss: 0.3827 - val_auc: 0.8880\n",
            "Epoch 491/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4043 - auc: 0.8697 - val_loss: 0.3836 - val_auc: 0.8867\n",
            "Epoch 492/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4031 - auc: 0.8713 - val_loss: 0.3845 - val_auc: 0.8915\n",
            "Epoch 493/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4031 - auc: 0.8700 - val_loss: 0.3826 - val_auc: 0.8870\n",
            "Epoch 494/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4027 - auc: 0.8701 - val_loss: 0.3829 - val_auc: 0.8895\n",
            "Epoch 495/600\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4048 - auc: 0.8715 - val_loss: 0.3830 - val_auc: 0.8900\n",
            "Epoch 496/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4039 - auc: 0.8700 - val_loss: 0.3828 - val_auc: 0.8916\n",
            "Epoch 497/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4043 - auc: 0.8692 - val_loss: 0.3824 - val_auc: 0.8854\n",
            "Epoch 498/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4043 - auc: 0.8687 - val_loss: 0.3842 - val_auc: 0.8871\n",
            "Epoch 499/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4026 - auc: 0.8715 - val_loss: 0.3830 - val_auc: 0.8878\n",
            "Epoch 500/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4044 - auc: 0.8698 - val_loss: 0.3836 - val_auc: 0.8884\n",
            "Epoch 501/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4044 - auc: 0.8710 - val_loss: 0.3834 - val_auc: 0.8881\n",
            "Epoch 502/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4040 - auc: 0.8708 - val_loss: 0.3837 - val_auc: 0.8856\n",
            "Epoch 503/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4065 - auc: 0.8681 - val_loss: 0.3837 - val_auc: 0.8854\n",
            "Epoch 504/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4040 - auc: 0.8689 - val_loss: 0.3838 - val_auc: 0.8871\n",
            "Epoch 505/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4031 - auc: 0.8704 - val_loss: 0.3829 - val_auc: 0.8853\n",
            "Epoch 506/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4043 - auc: 0.8702 - val_loss: 0.3829 - val_auc: 0.8867\n",
            "Epoch 507/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4042 - auc: 0.8680 - val_loss: 0.3832 - val_auc: 0.8879\n",
            "Epoch 508/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4035 - auc: 0.8711 - val_loss: 0.3833 - val_auc: 0.8873\n",
            "Epoch 509/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4029 - auc: 0.8716 - val_loss: 0.3834 - val_auc: 0.8903\n",
            "Epoch 510/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4030 - auc: 0.8703 - val_loss: 0.3838 - val_auc: 0.8864\n",
            "Epoch 511/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4035 - auc: 0.8712 - val_loss: 0.3834 - val_auc: 0.8907\n",
            "Epoch 512/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4035 - auc: 0.8697 - val_loss: 0.3833 - val_auc: 0.8874\n",
            "Epoch 513/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4023 - auc: 0.8713 - val_loss: 0.3840 - val_auc: 0.8884\n",
            "Epoch 514/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4025 - auc: 0.8702 - val_loss: 0.3838 - val_auc: 0.8917\n",
            "Epoch 515/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4033 - auc: 0.8688 - val_loss: 0.3848 - val_auc: 0.8864\n",
            "Epoch 516/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4025 - auc: 0.8694 - val_loss: 0.3842 - val_auc: 0.8890\n",
            "Epoch 517/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4025 - auc: 0.8712 - val_loss: 0.3839 - val_auc: 0.8901\n",
            "Epoch 518/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4022 - auc: 0.8711 - val_loss: 0.3838 - val_auc: 0.8877\n",
            "Epoch 519/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4045 - auc: 0.8681 - val_loss: 0.3852 - val_auc: 0.8888\n",
            "Epoch 520/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4024 - auc: 0.8711 - val_loss: 0.3836 - val_auc: 0.8873\n",
            "Epoch 521/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4025 - auc: 0.8701 - val_loss: 0.3838 - val_auc: 0.8912\n",
            "Epoch 522/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4029 - auc: 0.8689 - val_loss: 0.3834 - val_auc: 0.8879\n",
            "Epoch 523/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4022 - auc: 0.8708 - val_loss: 0.3833 - val_auc: 0.8851\n",
            "Epoch 524/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4032 - auc: 0.8711 - val_loss: 0.3840 - val_auc: 0.8898\n",
            "Epoch 525/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4024 - auc: 0.8707 - val_loss: 0.3839 - val_auc: 0.8918\n",
            "Epoch 526/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4034 - auc: 0.8708 - val_loss: 0.3837 - val_auc: 0.8882\n",
            "Epoch 527/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4037 - auc: 0.8695 - val_loss: 0.3841 - val_auc: 0.8902\n",
            "Epoch 528/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4032 - auc: 0.8711 - val_loss: 0.3837 - val_auc: 0.8896\n",
            "Epoch 529/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4035 - auc: 0.8719 - val_loss: 0.3842 - val_auc: 0.8883\n",
            "Epoch 530/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4030 - auc: 0.8712 - val_loss: 0.3841 - val_auc: 0.8882\n",
            "Epoch 531/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4021 - auc: 0.8714 - val_loss: 0.3840 - val_auc: 0.8875\n",
            "Epoch 532/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4021 - auc: 0.8718 - val_loss: 0.3839 - val_auc: 0.8879\n",
            "Epoch 533/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4026 - auc: 0.8710 - val_loss: 0.3842 - val_auc: 0.8885\n",
            "Epoch 534/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4022 - auc: 0.8723 - val_loss: 0.3852 - val_auc: 0.8861\n",
            "Epoch 535/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4025 - auc: 0.8699 - val_loss: 0.3845 - val_auc: 0.8920\n",
            "Epoch 536/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4026 - auc: 0.8703 - val_loss: 0.3845 - val_auc: 0.8886\n",
            "Epoch 537/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4042 - auc: 0.8683 - val_loss: 0.3842 - val_auc: 0.8881\n",
            "Epoch 538/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4022 - auc: 0.8710 - val_loss: 0.3841 - val_auc: 0.8912\n",
            "Epoch 539/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4025 - auc: 0.8705 - val_loss: 0.3845 - val_auc: 0.8900\n",
            "Epoch 540/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4019 - auc: 0.8700 - val_loss: 0.3845 - val_auc: 0.8863\n",
            "Epoch 541/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4020 - auc: 0.8712 - val_loss: 0.3855 - val_auc: 0.8912\n",
            "Epoch 542/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4058 - auc: 0.8688 - val_loss: 0.3850 - val_auc: 0.8888\n",
            "Epoch 543/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4020 - auc: 0.8721 - val_loss: 0.3848 - val_auc: 0.8881\n",
            "Epoch 544/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4025 - auc: 0.8701 - val_loss: 0.3847 - val_auc: 0.8871\n",
            "Epoch 545/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4035 - auc: 0.8705 - val_loss: 0.3846 - val_auc: 0.8860\n",
            "Epoch 546/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4025 - auc: 0.8692 - val_loss: 0.3851 - val_auc: 0.8915\n",
            "Epoch 547/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4024 - auc: 0.8718 - val_loss: 0.3841 - val_auc: 0.8862\n",
            "Epoch 548/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4026 - auc: 0.8704 - val_loss: 0.3843 - val_auc: 0.8916\n",
            "Epoch 549/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4016 - auc: 0.8704 - val_loss: 0.3859 - val_auc: 0.8880\n",
            "Epoch 550/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4034 - auc: 0.8697 - val_loss: 0.3844 - val_auc: 0.8899\n",
            "Epoch 551/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4045 - auc: 0.8671 - val_loss: 0.3845 - val_auc: 0.8875\n",
            "Epoch 552/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4016 - auc: 0.8719 - val_loss: 0.3854 - val_auc: 0.8882\n",
            "Epoch 553/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4035 - auc: 0.8689 - val_loss: 0.3845 - val_auc: 0.8868\n",
            "Epoch 554/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4014 - auc: 0.8717 - val_loss: 0.3852 - val_auc: 0.8861\n",
            "Epoch 555/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4075 - auc: 0.8697 - val_loss: 0.3843 - val_auc: 0.8873\n",
            "Epoch 556/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4049 - auc: 0.8708 - val_loss: 0.3853 - val_auc: 0.8854\n",
            "Epoch 557/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4015 - auc: 0.8706 - val_loss: 0.3860 - val_auc: 0.8918\n",
            "Epoch 558/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4023 - auc: 0.8707 - val_loss: 0.3843 - val_auc: 0.8917\n",
            "Epoch 559/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4018 - auc: 0.8702 - val_loss: 0.3847 - val_auc: 0.8884\n",
            "Epoch 560/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4016 - auc: 0.8707 - val_loss: 0.3857 - val_auc: 0.8918\n",
            "Epoch 561/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4029 - auc: 0.8699 - val_loss: 0.3868 - val_auc: 0.8888\n",
            "Epoch 562/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4035 - auc: 0.8697 - val_loss: 0.3855 - val_auc: 0.8849\n",
            "Epoch 563/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4028 - auc: 0.8711 - val_loss: 0.3852 - val_auc: 0.8882\n",
            "Epoch 564/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4018 - auc: 0.8706 - val_loss: 0.3857 - val_auc: 0.8864\n",
            "Epoch 565/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4016 - auc: 0.8711 - val_loss: 0.3852 - val_auc: 0.8888\n",
            "Epoch 566/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4023 - auc: 0.8702 - val_loss: 0.3855 - val_auc: 0.8898\n",
            "Epoch 567/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4020 - auc: 0.8706 - val_loss: 0.3857 - val_auc: 0.8908\n",
            "Epoch 568/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4028 - auc: 0.8705 - val_loss: 0.3860 - val_auc: 0.8859\n",
            "Epoch 569/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4012 - auc: 0.8706 - val_loss: 0.3851 - val_auc: 0.8917\n",
            "Epoch 570/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4018 - auc: 0.8714 - val_loss: 0.3844 - val_auc: 0.8914\n",
            "Epoch 571/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4068 - auc: 0.8715 - val_loss: 0.3848 - val_auc: 0.8857\n",
            "Epoch 572/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4039 - auc: 0.8704 - val_loss: 0.3848 - val_auc: 0.8881\n",
            "Epoch 573/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4013 - auc: 0.8711 - val_loss: 0.3844 - val_auc: 0.8898\n",
            "Epoch 574/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4036 - auc: 0.8714 - val_loss: 0.3852 - val_auc: 0.8893\n",
            "Epoch 575/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4013 - auc: 0.8731 - val_loss: 0.3848 - val_auc: 0.8910\n",
            "Epoch 576/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4021 - auc: 0.8695 - val_loss: 0.3846 - val_auc: 0.8904\n",
            "Epoch 577/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4016 - auc: 0.8714 - val_loss: 0.3846 - val_auc: 0.8856\n",
            "Epoch 578/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4013 - auc: 0.8702 - val_loss: 0.3847 - val_auc: 0.8856\n",
            "Epoch 579/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4031 - auc: 0.8707 - val_loss: 0.3851 - val_auc: 0.8880\n",
            "Epoch 580/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4019 - auc: 0.8713 - val_loss: 0.3847 - val_auc: 0.8870\n",
            "Epoch 581/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4026 - auc: 0.8703 - val_loss: 0.3848 - val_auc: 0.8881\n",
            "Epoch 582/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4036 - auc: 0.8707 - val_loss: 0.3859 - val_auc: 0.8892\n",
            "Epoch 583/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4015 - auc: 0.8722 - val_loss: 0.3849 - val_auc: 0.8912\n",
            "Epoch 584/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4027 - auc: 0.8718 - val_loss: 0.3862 - val_auc: 0.8908\n",
            "Epoch 585/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4015 - auc: 0.8706 - val_loss: 0.3852 - val_auc: 0.8855\n",
            "Epoch 586/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4013 - auc: 0.8717 - val_loss: 0.3862 - val_auc: 0.8888\n",
            "Epoch 587/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4013 - auc: 0.8716 - val_loss: 0.3858 - val_auc: 0.8854\n",
            "Epoch 588/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4019 - auc: 0.8706 - val_loss: 0.3849 - val_auc: 0.8910\n",
            "Epoch 589/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4016 - auc: 0.8703 - val_loss: 0.3856 - val_auc: 0.8880\n",
            "Epoch 590/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4023 - auc: 0.8711 - val_loss: 0.3849 - val_auc: 0.8897\n",
            "Epoch 591/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4023 - auc: 0.8709 - val_loss: 0.3850 - val_auc: 0.8857\n",
            "Epoch 592/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4037 - auc: 0.8705 - val_loss: 0.3851 - val_auc: 0.8899\n",
            "Epoch 593/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4030 - auc: 0.8707 - val_loss: 0.3855 - val_auc: 0.8853\n",
            "Epoch 594/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4030 - auc: 0.8712 - val_loss: 0.3861 - val_auc: 0.8901\n",
            "Epoch 595/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4014 - auc: 0.8722 - val_loss: 0.3852 - val_auc: 0.8860\n",
            "Epoch 596/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4010 - auc: 0.8706 - val_loss: 0.3849 - val_auc: 0.8913\n",
            "Epoch 597/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4013 - auc: 0.8724 - val_loss: 0.3869 - val_auc: 0.8895\n",
            "Epoch 598/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4032 - auc: 0.8682 - val_loss: 0.3854 - val_auc: 0.8858\n",
            "Epoch 599/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4025 - auc: 0.8704 - val_loss: 0.3856 - val_auc: 0.8884\n",
            "Epoch 600/600\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4026 - auc: 0.8704 - val_loss: 0.3865 - val_auc: 0.8886\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fcf2c6d0f98>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m43qsxGC7oIl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "5dff13c2-56d7-4733-d209-0ce37f251234"
      },
      "source": [
        "y_pred = model.predict_classes(df1)\n",
        "\n",
        "#roc_auc_score(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-74-47c122742749>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYdPRRvJ8q0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdF7kDoB8vDX",
        "colab_type": "text"
      },
      "source": [
        "# Crreate submission file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Au3FbZNc80AS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Survived = np.squeeze(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1r8yDeb9hbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PassengerId = np.arange(892,1310)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWRnBheS96Bw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "571da07d-13ad-41aa-971a-f2b06581786d"
      },
      "source": [
        "ans = pd.DataFrame(list(zip(PassengerId,Survived)),columns=['PassengerId','Survived'])\n",
        "ans.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>892</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>893</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>894</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>895</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>896</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived\n",
              "0          892         0\n",
              "1          893         0\n",
              "2          894         0\n",
              "3          895         0\n",
              "4          896         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dk3E6a7o-nde",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9686a905-c3b5-4a11-d366-5ab4335cba0a"
      },
      "source": [
        "ans.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(418, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPqnTaYEADXm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans.to_csv('/content/drive/My Drive/Titanic problem/ans.csv',index =False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od3d0EXZBsoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}